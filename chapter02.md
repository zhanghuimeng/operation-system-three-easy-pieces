# 第二章 操作系统简介

如果你正在上一门本科生的操作系统课程，你应该已经了解程序运行时的行为了。如果你还不了解这一过程的话，这本书（和对应的课程）将会很难——因此你大概应该停止阅读这本书，然后跑到最近的书店买上一本介绍必要的背景材料的书再继续（Patt/Patel{{ "PP03" | cite }}和Bryant/O'Hallaron{{ "BOH10" | cite }}的书的很棒，特别是后一本）。

所以，程序运行时到底会发生什么呢？

实际上，正在运行的程序只会做一件非常简单的事：执行指令。处理器以每秒几百万次（现在甚至可能是数十亿次了）的速度从内存**取指**，对指令进行**译码**（即确定这条指令是什么），并**执行**指令（即执行指令内容，比如将两个数相加，访问内存，检查状态，跳转到函数，等等）。CPU执行完一条指令之后便继续执行下一条指令，如此继续，直到程序最终执行完[^1]。

这样，我们就介绍完了**冯·诺依曼（Von Neumann）计算机模型**的基本要素[^2]。听起来很简单吧？但在课程中，我们会了解到，在程序运行过程中，为了保证系统的**易用性**，我们还需要做很多疯狂的事情。

事实上，有一类软件的功能就是保证容易运行程序（甚至允许你看起来好像能同时运行很多个程序），允许程序分享内存，使得程序能够和外部设备交互，还有很多其他有趣的东西。这一类软件就是**操作系统**（operating system）[^3]，它的工作就是保证系统高效正确运行，以及易用性。

<table><tr><td bgcolor=#E6E6E6>
<p style="text-align: center;"><strong>问题的症结：</strong></p>

<p style="text-align: center;"><strong>如何将资源虚拟化</strong></p>

<p>我们将在本书中回答的一个中心问题听起来相当简单：操作系统如何将资源虚拟化？这是我们的问题症结。操作系统<I>为什么</I>这么做并不是主要问题，因为答案是显然的：这会使得系统更易用。因此，我们的重点是<I>如何</I>进行虚拟化：操作系统实现了什么机制和策略用以实现虚拟化？如何提高虚拟化的效率？需要什么硬件支持？</p>

<p>我们将在像这样的阴影区域内标出“问题的症结”，用以强调我们在建造操作系统中试图解决的特定问题。因而，在某一主题对应的章节里，你会发现有不止一个<I>症结</I>强调了需要解决的问题。这一章里的细节则肯定会给出解决方案，至少是解决方案的基本属性。</p>

</td></tr></table>

操作系统进行虚拟化的主要方式是我们称之为**虚拟化**的通用技术，即操作系统将**物理**资源（比如处理器、内存和磁盘）并将其转化为一种更通用、更强有力、更易用的**虚拟**形式。因此，我们有时称操作系统为**虚拟机**。

当然，为了允许用户控制操作系统的行为，并使用虚拟机的特性（比如允许程序、分配内存或访问文件），操作系统也为用户提供了一些接口（API）。事实上，一个典型的操作系统会给应用程序提供几百种**系统调用**（system call）。因为操作系统为运行程序、访问内存和外部设备等行为提供了这些方法，我们有时也说操作系统为应用程序提供了一套**标准程序库**（standard library）。

因为虚拟化允许很多程序同时运行（也即共享CPU），这些程序会并发地访问自己的指令和数据（也即共享内存）以及外部设备（也即共享磁盘等等），操作系统有时也会被称为**资源管理程序**（resource manager）。CPU、内存和磁盘都是系统**资源**；操作系统的任务就是高效公平地**管理**这些资源。为了更好地理解操作系统的功能，让我们来看一些例子。

```c
#include <stdio.h>
#include <stdlib.h>
#include <sys/time.h>
#include <assert.h>
#include "common.h"

int
main(int argc, char *argv[])
{
    if (argc != 2) {
        fprintf(stderr, "usage: cpu <string>\n");
    exit(1);
    }
    char *str = argv[1];
    while (1) {
        Spin(1);
        printf("%s\n", str);
    }
    return 0;
}
```
<p style="text-align: center">图2.1：<strong>简单的例子：进行循环打印的代码（<code>cpu.c</code>）</strong></p>

## 2.1 对CPU进行虚拟化

图2.1描述了我们的第一个程序。它做的事情并不多。事实上，它的主要功能是调用`Spin()`函数，这一函数会不断检查时间，并在运行了恰好一秒钟之后返回。然后，它就会打印出用户通过命令行传入的参数字符串，并永远重复下去。

假设我们将这个程序保存为`cpu.c`并决定在一个单处理器（或者简单的称为**CPU**）系统上编译运行，我们将会看到如下输出：

```
prompt> gcc -o cpu cpu.c -Wall
prompt> ./cpu "A"
A
A
A
A
ˆC
prompt>
```

这次运行并不是很有趣——系统开始运行程序，程序开始不断检查时间，每经过一秒钟，代码就把用户传入的字符串（在例子中是字母“A”）打印出来。请注意，这个冲虚会永远运行下去；只有按下“Ctrl+C”（在UNIX系统中会终止前台进程）才能中止程序运行。

下面，让我们继续运行相同的程序，但这次同时运行同一程序的不同实例。图2.2展示了这一稍微复杂一些的运行结果。

```
prompt> ./cpu A & ; ./cpu B & ; ./cpu C & ; ./cpu D &
[1] 7353
[2] 7354
[3] 7355
[4] 7356
A 
B 
D 
C 
A 
B 
D 
C 
A 
C 
B 
D
...
```
<p style="text-align: center">图2.2：<strong>同时运行多个程序</strong></p>

现在事情开始变得更有趣了。即使我们只有一个处理器，四个程序仍然看起来好像在同时运行！为什么会发生这么神奇的事情呢？[^4]

事实证明，在硬件的帮助下，操作系统能够产生这种**错觉**，即系统拥有非常多的的虚拟CPU。 我们所说的**CPU的虚拟化**指的就是将一个CPU（或几个CPU）转化成看起来无限多的CPU，从而允许很多程序似乎能同时运行，这是本书第一部分的重点。

当然，为了运行和暂停程序，或者告诉操作系统要运行哪些程序，你需要一些接口（API）用来和操作系统交流。我们会在本书中讨论这些API；的确，它们是用户和操作系统互动的主要方式。

你可能还会注意到，同时运行多个程序的能力引发了各种各样的新问题。例如，假设有两个程序同时需要运行，**应该**运行哪一个？操作系统的一种**策略**（policy）解决了这一问题。在操作系统中，为了解决这一类问题，各种各样的策略被应用在各处，以后我们学习到操作系统实现的基本**机制**（比如同时运行多个程序的能力）时也会了解这些策略。这就是操作系统被称为**资源管理程序**的原因。

## 2.2 内存的虚拟化

现在让我们考虑内存。现代计算机提供的**物理内存**模型是非常简单的。内存只不过是一个字节数组；**读**内存的方法是提供**地址**用以访问该地址处的数据；**写**（或者**更新**）内存时还需要给出写入给定地址的数据。

程序运行时始终在访问内存，它把全部的数据结构都保存在内存中，并在工作过程中通过各种各样的指令访问数据，包括加载存储指令和其他直接访问内存的指令。

```c
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include "common.h"
int
main(int argc, char *argv[])
{
    int *p = malloc(sizeof(int));                   // a1
    assert(p != NULL);
    printf("(%d) address pointed to by p: %p\n",
           getpid(), p);                            // a2
    *p = 0;                                         // a3
    while (1) {
        Spin(1);
        *p = *p + 1;
        printf("(%d) p: %d\n", getpid(), *p);       // a4
    }
    return 0;
}
```
<p style="text-align: center">图2.3：<strong>访问内存的程序（<code>mem.c</code>）</strong></p>

让我们看看图2.3中通过`malloc()`函数分配内存的程序。程序输出如下：

```
prompt> ./mem
(2134) address pointed to by p: 0x200000
(2134) p: 1
(2134) p: 2
(2134) p: 3
(2134) p: 4
(2134) p: 5
ˆC
```

这个程序做了以下几件事。首先，它分配了一些内存（见a1行）。然后它打印出内存的地址（a2），并将0存入新分配的内存的第一个字节中。最后，程序进入循环，等待1秒钟，然后将`p`中存储的地址处的值+1。在打印该值的同时，程序也打印出了正在运行的程序的进程标识符（process identifier，PID）。每个进程的PID都是不同的。

这次的结果同样不太有趣。新分配的内存位于地址`0x200000`。在程序运行过程中，它缓慢更新该地址处的值并打印出结果。

```
prompt> ./mem &; ./mem &
[1] 24113
[2] 24114
(24113) address pointed to by p: 0x200000
(24114) address pointed to by p: 0x200000
(24113) p: 1
(24114) p: 1
(24114) p: 2
(24113) p: 2
(24113) p: 3
(24114) p: 3
(24113) p: 4
(24114) p: 4
...
```
<p style="text-align: center">图2.4：<strong>同时运行多个访存程序</strong></p>

现在我们再次同时运行这个程序的多个实例，看看会发生什么（图2.4）。我们可以从例子发现，每个运行中的程序都在同一地址（`0x200000`）分配内存，而且似乎在各自独立地更新`0x200000`处的值！这就好像是每个运行的程序不是和别的程序共享同一个物理内存，而都拥有自己的内存那样。[^5]

的确，这是因为操作系统实现了**内存的虚拟化**。每个进程访问的都是自己的**虚地址空间**（virtual address space）（有时简称为**地址空间**），操作系统将这些地址通过某种方法映射到机器的物理内存上。一个运行中的程序的访存不会影响其他进程（和操作系统自己）的地址空间，就好像它拥有全部的物理内存那样。然而，物理内存实际上是由操作系统管理的共享资源。如何实现共享内存也是本书第一部分，**虚拟化**的内容之一。

## 2.3 并发
本书的另一个主题概念是**并发**（concurrency）。这一抽象概念指的是，在同一程序内同时（也就是并发地）做很多事时，可能出现并且必须解决的一类问题。操作系统自己内部就会出现并发问题：就像你在上面的虚拟化的例子中看到的那样，操作系统同时处理着很多事情，运行完一个进程又切换到下一个，等等。事实上，这样做会导致一些有趣而深刻的问题。

```c
#include <stdio.h>
#include <stdlib.h>
#include "common.h"

volatile int counter = 0;
int loops;

void *worker(void *arg) {
    int i;
    for (i = 0; i < loops; i++) {
        counter++;
    }
    return NULL;
}

int
main(int argc, char *argv[])
{
    if (argc != 2) {
        fprintf(stderr, "usage: threads <value>\n");
        exit(1);
    }
    loops = atoi(argv[1]);
    pthread_t p1, p2;
    printf("Initial value : %d\n", counter);

    Pthread_create(&p1, NULL, worker, NULL);
    Pthread_create(&p2, NULL, worker, NULL);
    Pthread_join(p1, NULL);
    Pthread_join(p2, NULL);
    printf("Final value : %d\n", counter);
    return 0;
}
```
<p style="text-align: center">图2.5：<strong>一个多线程程序（<code>threads.c</code>）</strong></p>

不幸的是，并发问题不止会出现在操作系统内部，事实上，现代的**多线程**（multi-thread）程序会遇到相同的问题。让我们用一个**多线程**的程序来演示一下这个问题（图2.5）。

---

[^1] 显然，为了使程序运行得更快，现代处理器暗中做了很多骇人听闻的事情，比如同时执行多条指令，甚至乱序发射和执行指令！但我们并不关心这些；我们只关心大部分程序假设的简单模型：指令按顺序执行，一次只执行一条。

[^2] 冯·诺依曼是计算机领域的先驱者之一。他同时也在博弈论和原子弹领域进行了开创性的工作，并在NBA中打了六年球。好吧，以上有一件事不是真的。（译者：在NBA打球不是真的。）

[^3] 操作系统的其他早期名称包括**监督程序**（supervisor），以及**中央控制程序**（master control program）。显然，第二个名字听起来有点过于心急了（细节请见电影《电子世界争霸战》（Tron））；因此，谢天谢地，最终人们采用了“操作系统”这一名称。（译者：“中央控制程序”是[该电影](https://en.wikipedia.org/wiki/Tron)中不愿被人操纵而想掌控世界的人工智能的名字。）

[^4] 我们使用`&`符号来同时运行四个进程。在`tcsh`终端中，这样做会在后台启动这些程序，也就意味着用户可以立即给出下一条指令，此处是下一个要运行的程序。在`tcsh`中，命令之间的分号允许我们同时运行多个程序。如果你使用的是其他终端（比如`bash`），表现会有一些不同，具体请阅读在线文档。

[^5] 为了使这个例子能够工作，你需要关闭地址空间随机化（address-space randomization）；事实上，随机化可以很好地抵挡某些安全漏洞。如果你想了解如何通过栈溢出攻击破解计算机系统，请自己阅读更多相关内容。当然这并不是说我们建议这么做……