# 第二章 操作系统简介

如果你正在上一门本科生的操作系统课程，你应该已经了解程序运行时的行为了。如果你还不了解这一过程的话，这本书（和对应的课程）将会很难——因此你大概应该停止阅读这本书，然后跑到最近的书店买上一本介绍必要的背景材料的书再继续（Patt/Patel{{ "PP03" | cite }}和Bryant/O'Hallaron{{ "BOH10" | cite }}的书的很棒，特别是后一本）。

所以，程序运行时到底会发生什么呢？

实际上，正在运行的程序只会做一件非常简单的事：执行指令。处理器以每秒几百万次（现在甚至可能是数十亿次了）的速度从内存**取指**，对指令进行**译码**（即确定这条指令是什么），并**执行**指令（即执行指令内容，比如将两个数相加，访问内存，检查状态，跳转到函数，等等）。CPU执行完一条指令之后便继续执行下一条指令，如此继续，直到程序最终执行完[^1]。

这样，我们就介绍完了**冯·诺依曼（Von Neumann）计算机模型**的基本要素[^2]。听起来很简单吧？但在课程中，我们会了解到，在程序运行过程中，为了保证系统的**易用性**，我们还需要做很多疯狂的事情。

事实上，有一类软件的功能就是保证容易运行程序（甚至允许你看起来好像能同时运行很多个程序），允许程序分享内存，使得程序能够和外部设备交互，还有很多其他有趣的东西。这一类软件就是**操作系统**（operating system）[^3]，它的工作就是保证系统高效正确运行，以及易用性。

<table><tr><td bgcolor=#E6E6E6>
<p style="text-align: center;"><strong>问题的症结：</strong></p>

<p style="text-align: center;"><strong>如何将资源虚拟化</strong></p>

<p>我们将在本书中回答的一个中心问题听起来相当简单：操作系统如何将资源虚拟化？这是我们的问题症结。操作系统<I>为什么</I>这么做并不是主要问题，因为答案是显然的：这会使得系统更易用。因此，我们的重点是<I>如何</I>进行虚拟化：操作系统实现了什么机制和策略用以实现虚拟化？如何提高虚拟化的效率？需要什么硬件支持？</p>

<p>我们将在像这样的阴影区域内标出“问题的症结”，用以强调我们在建造操作系统中试图解决的特定问题。因而，在某一主题对应的章节里，你会发现有不止一个<I>症结</I>强调了需要解决的问题。这一章里的细节则肯定会给出解决方案，至少是解决方案的基本属性。</p>

</td></tr></table>

操作系统进行虚拟化的主要方式是我们称之为**虚拟化**的通用技术，即操作系统将**物理**资源（比如处理器、内存和磁盘）并将其转化为一种更通用、更强有力、更易用的**虚拟**形式。因此，我们有时称操作系统为**虚拟机**。

当然，为了允许用户控制操作系统的行为，并使用虚拟机的特性（比如允许程序、分配内存或访问文件），操作系统也为用户提供了一些接口（API）。事实上，一个典型的操作系统会给应用程序提供几百种**系统调用**（system call）。因为操作系统为运行程序、访问内存和外部设备等行为提供了这些方法，我们有时也说操作系统为应用程序提供了一套**标准程序库**（standard library）。

因为虚拟化允许很多程序同时运行（也即共享CPU），这些程序会并发地访问自己的指令和数据（也即共享内存）以及外部设备（也即共享磁盘等等），操作系统有时也会被称为**资源管理程序**（resource manager）。CPU、内存和磁盘都是系统**资源**；操作系统的任务就是高效公平地**管理**这些资源。为了更好地理解操作系统的功能，让我们来看一些例子。

```c
#include <stdio.h>
#include <stdlib.h>
#include <sys/time.h>
#include <assert.h>
#include "common.h"

int
main(int argc, char *argv[])
{
    if (argc != 2) {
        fprintf(stderr, "usage: cpu <string>\n");
    exit(1);
    }
    char *str = argv[1];
    while (1) {
        Spin(1);
        printf("%s\n", str);
    }
    return 0;
}
```
<p style="text-align: center">图2.1：<strong>简单的例子：进行循环打印的代码（<code>cpu.c</code>）</strong></p>

## 2.1 对CPU进行虚拟化

图2.1描述了我们的第一个程序。它做的事情并不多。事实上，它的主要功能是调用`Spin()`函数，这一函数会不断检查时间，并在运行了恰好一秒钟之后返回。然后，它就会打印出用户通过命令行传入的参数字符串，并永远重复下去。

假设我们将这个程序保存为`cpu.c`并决定在一个单处理器（或者简单的称为**CPU**）系统上编译运行，我们将会看到如下输出：

```
prompt> gcc -o cpu cpu.c -Wall
prompt> ./cpu "A"
A
A
A
A
ˆC
prompt>
```

这次运行并不是很有趣——系统开始运行程序，程序开始不断检查时间，每经过一秒钟，代码就把用户传入的字符串（在例子中是字母“A”）打印出来。请注意，这个冲虚会永远运行下去；只有按下“Ctrl+C”（在UNIX系统中会终止前台进程）才能中止程序运行。

下面，让我们继续运行相同的程序，但这次同时运行同一程序的不同实例。图2.2展示了这一稍微复杂一些的运行结果。

```
prompt> ./cpu A & ; ./cpu B & ; ./cpu C & ; ./cpu D &
[1] 7353
[2] 7354
[3] 7355
[4] 7356
A 
B 
D 
C 
A 
B 
D 
C 
A 
C 
B 
D
...
```
<p style="text-align: center">图2.2：<strong>同时运行多个程序</strong></p>

现在事情开始变得更有趣了。即使我们只有一个处理器，四个程序仍然看起来好像在同时运行！为什么会发生这么神奇的事情呢？[^4]

事实证明，在硬件的帮助下，操作系统能够产生这种**错觉**，即系统拥有非常多的的虚拟CPU。 我们所说的**CPU的虚拟化**指的就是将一个CPU（或几个CPU）转化成看起来无限多的CPU，从而允许很多程序似乎能同时运行，这是本书第一部分的重点。

当然，为了运行和暂停程序，或者告诉操作系统要运行哪些程序，你需要一些接口（API）用来和操作系统交流。我们会在本书中讨论这些API；的确，它们是用户和操作系统互动的主要方式。

你可能还会注意到，同时运行多个程序的能力引发了各种各样的新问题。例如，假设有两个程序同时需要运行，**应该**运行哪一个？操作系统的一种**策略**（policy）解决了这一问题。在操作系统中，为了解决这一类问题，各种各样的策略被应用在各处，以后我们学习到操作系统实现的基本**机制**（比如同时运行多个程序的能力）时也会了解这些策略。这就是操作系统被称为**资源管理程序**的原因。

## 2.2 内存的虚拟化

现在让我们考虑内存。现代计算机提供的**物理内存**模型是非常简单的。内存只不过是一个字节数组；**读**内存的方法是提供**地址**用以访问该地址处的数据；**写**（或者**更新**）内存时还需要给出写入给定地址的数据。

程序运行时始终在访问内存，它把全部的数据结构都保存在内存中，并在工作过程中通过各种各样的指令访问数据，包括加载存储指令和其他直接访问内存的指令。

```c
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include "common.h"
int
main(int argc, char *argv[])
{
    int *p = malloc(sizeof(int));                   // a1
    assert(p != NULL);
    printf("(%d) address pointed to by p: %p\n",
           getpid(), p);                            // a2
    *p = 0;                                         // a3
    while (1) {
        Spin(1);
        *p = *p + 1;
        printf("(%d) p: %d\n", getpid(), *p);       // a4
    }
    return 0;
}
```
<p style="text-align: center">图2.3：<strong>访问内存的程序（<code>mem.c</code>）</strong></p>

让我们看看图2.3中通过`malloc()`函数分配内存的程序。程序输出如下：

```
prompt> ./mem
(2134) address pointed to by p: 0x200000
(2134) p: 1
(2134) p: 2
(2134) p: 3
(2134) p: 4
(2134) p: 5
ˆC
```

这个程序做了以下几件事。首先，它分配了一些内存（见a1行）。然后它打印出内存的地址（a2），并将0存入新分配的内存的第一个字节中。最后，程序进入循环，等待1秒钟，然后将`p`中存储的地址处的值+1。在打印该值的同时，程序也打印出了正在运行的程序的进程标识符（process identifier，PID）。每个进程的PID都是不同的。

这次的结果同样不太有趣。新分配的内存位于地址`0x200000`。在程序运行过程中，它缓慢更新该地址处的值并打印出结果。

```
prompt> ./mem &; ./mem &
[1] 24113
[2] 24114
(24113) address pointed to by p: 0x200000
(24114) address pointed to by p: 0x200000
(24113) p: 1
(24114) p: 1
(24114) p: 2
(24113) p: 2
(24113) p: 3
(24114) p: 3
(24113) p: 4
(24114) p: 4
...
```
<p style="text-align: center">图2.4：<strong>同时运行多个访存程序</strong></p>

现在我们再次同时运行这个程序的多个实例，看看会发生什么（图2.4）。我们可以从例子发现，每个运行中的程序都在同一地址（`0x200000`）分配内存，而且似乎在各自独立地更新`0x200000`处的值！这就好像是每个运行的程序不是和别的程序共享同一个物理内存，而都拥有自己的内存那样。[^5]

的确，这是因为操作系统实现了**内存的虚拟化**。每个进程访问的都是自己的**虚地址空间**（virtual address space）（有时简称为**地址空间**），操作系统将这些地址通过某种方法映射到机器的物理内存上。一个运行中的程序的访存不会影响其他进程（和操作系统自己）的地址空间，就好像它拥有全部的物理内存那样。然而，物理内存实际上是由操作系统管理的共享资源。如何实现共享内存也是本书第一部分，**虚拟化**的内容之一。

## 2.3 并发
本书的另一个主题概念是**并发**（concurrency）。这一抽象概念指的是，在同一程序内同时（也就是并发地）做很多事时，可能出现并且必须解决的一类问题。操作系统自己内部就会出现并发问题：就像你在上面的虚拟化的例子中看到的那样，操作系统同时处理着很多事情，运行完一个进程又切换到下一个，等等。事实上，这样做会导致一些有趣而深刻的问题。

```c
#include <stdio.h>
#include <stdlib.h>
#include "common.h"

volatile int counter = 0;
int loops;

void *worker(void *arg) {
    int i;
    for (i = 0; i < loops; i++) {
        counter++;
    }
    return NULL;
}

int
main(int argc, char *argv[])
{
    if (argc != 2) {
        fprintf(stderr, "usage: threads <value>\n");
        exit(1);
    }
    loops = atoi(argv[1]);
    pthread_t p1, p2;
    printf("Initial value : %d\n", counter);

    Pthread_create(&p1, NULL, worker, NULL);
    Pthread_create(&p2, NULL, worker, NULL);
    Pthread_join(p1, NULL);
    Pthread_join(p2, NULL);
    printf("Final value : %d\n", counter);
    return 0;
}
```
<p style="text-align: center">图2.5：<strong>一个多线程程序（<code>threads.c</code>）</strong></p>

不幸的是，并发问题不止会出现在操作系统内部，事实上，现代的**多线程**（multi-thread）程序会遇到相同的问题。让我们用一个**多线程**的程序来演示一下这个问题（图2.5）。

<table><tr><td bgcolor=#E6E6E6>
<p style="text-align: center;"><strong>问题的症结：</strong></p>

<p style="text-align: center;"><strong>如何编写正确的并发程序</strong></p>

<p>当很多线程在同一地址空间内并发执行时，如何编写一个能正确工作的程序？我们需要操作系统提供什么原语（primitive）？硬件需要提供什么机制？我们如何使用这些工具来解决并发问题？</p>

</td></tr></table>

虽然你此时可能还无法完全理解这个例子（在之后关于并发的的章节中，我们会学到更多多线程知识），它的基本思想是很简单的。主程序用`Pthread_create()`[^6]函数创建了两个**线程**。你可以认为一个线程是和其他函数在同一个地址空间中运行的函数，而且同时有多个函数在运行。在这个例子中，每个线程都运行一个叫做`worker()`的程序片段，它会在循环中将计数器`counter`增加`loops`次。

下面是输入的`loops`变量的值为1000时的输出。`loops`的值决定了两个`worker`线程各自会增加共享计数器多少次。当`loops`被设置为1000时，你认为`counter`最终的值是多少呢？

```
prompt> gcc -o thread thread.c -Wall -pthread
prompt> ./thread 1000
Initial value : 0
Final value : 2000
```

你可能已经猜到了，当这两个线程都运行结束时，计数器的值为2000，因为每个线程都会增加计数器1000次。的确，当我们把输入的`loops`的值设置为$$N$$时，可以期望程序的输出为$$2N$$。但事实上，生活并非这么简单。让我们把`loops`的值调高，重新运行同样的程序，看看会发生什么：

```
prompt> ./thread 100000
Initial value : 0
Final value : 143012 // huh??
prompt> ./thread 100000
Initial value : 0
Final value : 137298 // what the??
```

在这次运行中，当我们输入的值为100000时，程序没有输出200000，而是输出了143012。然后，当我们再次运行程序的时候，我们不仅得到了*错误*的值，这个值和上次的结果还是*不同*的。事实上，如果你用更大的`loops`的值一遍遍地运行这一程序，你可能会发现，有时甚至得到了正确答案！到底为什么会这样呢？

实际上，这些不同寻常的结果与指令每次只执行一条有关。不幸的是，在上述程序的关键部分中，增加共享计数器需要三条指令：从内存中加载计数器的值到寄存器，将这个值+1，最后再把新的值存储回内存中。因为这三条指令不是**原子地**（atomically）执行的（即连续执行），因此就会发生奇怪的事情。这一问题就是由**并发**引起的，我们将会在本书的第二部分仔细讨论这一问题。

## 2.4 持久化

本课程的第三个主题是持久化（persistence）。系统内存这种的数据很容易丢失，因为DRAM等存储器是**易失的**（volatile）；断电或系统崩溃时，内存中的全部数据都会丢失。因此，我们需要能够**持久**存储数据的硬件和软件；这样的存储方式对任何系统都是很重要的，因为用户非常在乎他们的数据。

这样的硬件是以**输入/输出**（input/output，I/O）设备的形式出现的。在现代系统中，**硬盘**（hard drive）通常被用来长期存储信息，不过最近**固态硬盘**（solid-state drive，SSD）也在迎头赶上。

操作系统内部用于管理磁盘的软件叫做**文件系统**（file system）；它的功能是高效可靠地把用户创建的任何**文件**存储在系统的磁盘中。

操作系统并不会为每个应用像虚拟CPU和虚拟内存那样创建一个虚拟的磁盘，而是假设用户通常会想要**共享**存储在文件中信息。例如，在编写一个C程序的时候，你可能会首先使用一个编辑器（比如Emacs[^7]）创建和编辑C程序文件（`emacs -nw main.c`）。写完之后，你可能就需要用编译器将源文件编译成可执行文件（比如`gcc -o main main.c`）。当你编译完之后，你就可以运行可执行文件（比如`./main`）。文件就是这样由不同的进程共享的。Emacs首先创建了编译器的输入文件；编译器将这个文件编译成新的可执行文件（通过很多步——细节详见编译课程）；最后执行这个可执行文件。一个新的程序就这样诞生了！

```c
#include <stdio.h>
#include <unistd.h>
#include <assert.h>
#include <fcntl.h>
#include <sys/types.h>
int
main(int argc, char *argv[])
{
    int fd = open("/tmp/file", O_WRONLY | O_CREAT | O_TRUNC, S_IRWXU);
    assert(fd > -1);
    int rc = write(fd, "hello world\n", 13);
    assert(rc == 13);
    close(fd);
    return 0;
}
```
<p style="text-align: center">图2.6：<strong>一个进行I/O的程序<code>io.c</code>）</strong></p>

为了更好地理解这些，让我们来看一些示例代码。图2.6中的代码创建了一个包含字符串“hello world”的文件（在`/tmp/file`）目录下。

<table><tr><td bgcolor=#E6E6E6>
<p style="text-align: center;"><strong>问题的症结：</strong></p>

<p style="text-align: center;"><strong>如何持久化存储数据</strong></p>

<p>操作系统的功能之一是用文件系统来管理持久化数据。正确管理数据需要什么技术？使用什么机制和策略才能提高性能？面对硬件和软件的错误，如何获得可靠性？</p>

</td></tr></table>

为了完成这一任务，程序向操作系统发送了三次请求。第一次调用了`open()`函数，创建并发开文件；第二次调用了`write()`函数，向文件中写入一些数据；最后调用了`close()`函数，将文件关闭，不再向文件中写入更多数据。这些**系统调用**被传递到操作系统内部的**文件系统**，处理这些请求并返回错误代码。

你可能想知道操作系统需要做什么才能实际写入硬盘中。我们接下来会讲解这一点，但你必须先闭上双眼认真听讲，因为实在是太无聊了。文件系统需要做的事情相当多：首先找出新的数据将位于磁盘的哪个位置，然后在文件系统内部的许多结构中跟踪这一位置。需要向底层的存储设备发送I/O请求，用来读取或更新（写入）现存的结构化数据。写过**设备驱动程序**（device driver）[^8]的人都知道，让设备帮助你做一些事情是一项非常复杂精细的工作。这项工作需要对底层设备的接口和语义有深刻的了解。幸运的是，操作系统通过系统调用提供了一种简单标准地访问设备的方法。因此，操作系统有时被看成是一个**标准程序库**。

当然，访问设备以及操作系统如何在上述设备中持久化管理数据还有很多细节。为了提高性能，现在的大多数文件系统都会先推迟写操作一段时间，希望能把操作分成更大的组。为了处理写操作中系统崩溃的问题，大多数文件系统都应用了某些复杂的写协议，比如**日志**（journaling）和**写时复制**（copy-on-write），仔细安排对磁盘的写操作，用以确保如果写过程中发生错误，系统随后可以恢复到一个合理的状态。为了加速各类操作，文件系统应用了许多不同的数据结构和访问方法，从简单的链表到复杂的B树。如果这些你都听不懂，非常高！我们在本书的第三部分，**持久化**中，会花大量时间学习这些东西。我们会详细讲解广义上的设备和I/O、磁盘、RAID和文件系统。

## 2.5 设计目标

现在你已经对操作系统的功能有一些基本了解了：它将CPU、内存、磁盘等物理**资源**转换成虚拟资源，处理与**并发**相关的困难问题，并**持久化**地存储数据，让数据的撑起存储更安全。因为我们想建造一个这样的系统，为了专注于设计实现和必要的权衡，我们需要在头脑中明确一些目标；进行必要的取舍是建造系统的关键。

我们的基础目标之一是建立一些**抽象**（abstraction）用以使系统使用更简单方便。抽象化对于计算机科学中的一切都非常重要：抽象化使得我们能够将大型程序分解成容易理解的比较小的部分，能够用像C[^9]这样的高级语言编程而不必一直使用汇编，能够用汇编编写代码而不必画出逻辑电路，能够用逻辑电路构建CPU而不必一直想着晶体管。抽象是如此基本，以至于有时我们都忘掉了它的重要性，但在此处不会；因此，在每个部分中，我们都会讨论操作系统使用的一些主要抽象，让你能够思考操作系统的某些部分。

设计和实现操作系统中的另一个目标是提供高**性能**；另一种说法是**代价最小化**。虚拟化和系统的易用性是必要的，但也是有代价的；因此，我们必须努力在不太多的代价下提供虚拟化和其他的操作系统特性。代价会以几种方式出现：更多的时间（更多的指令）和更多的空间（磁盘或内存）。我们会尽可能地寻找最小化其中一种或全部代价的方法。然而，并不是总能达到尽善尽美，我们将会认识到并容忍（在合理限度下）这一点。

另一个目标是在应用之间以及操作系统和应用之间提供**保护**。因为我们希望同时运行多个程序，需要保证其中某些程序的恶意或偶然行为危害到其他程序；当然也不能危害到操作系统本身（这样就会影响系统上运行的*所有*程序）。保护是操作系统内部的主要原则之一，**隔离**（isolation）的核心要素；将进程互相隔离是进行保护的基本方法，这是操作系统的基本功能。

操作系统必须不间断地运行；当它中断的时候，系统上运行的*全部*程序也会中断。由于这种依赖性，操作系统必须努力提供非常高的**可靠性**。因为操作系统在不断地变得更加复杂（有时包含了几百万行代码），建立一个可靠的操作系统是很有挑战性的——的确，这一领域中很多正在进行的研究（包括我们自己的一些研究{{ "BS_09" | cite }}{{ "SS_10" | cite }}）都是关于这一主题的。

还有一些其他的目标：**能效**（energy-efficiency）在这个越来越绿色的世界中很重要；在互联网时代，抵抗恶意应用的**安全性**（实际上是保护的扩展）也是关键的；由于操作系统正在越来越小的设备上运行，**可移动性**（mobility）也在变得日益重要起来。操作系统的目标取决于系统的应用场景，实现方式也会有稍许不同。不过，我们将会看到，这里的关于如何构建操作系统的很多原则对一系列不同的设备都很有用。

## 2.6 一些历史

在结束这一章的介绍之前，让我们看看操作系统的发展简史。就像任何人类建造的系统那样，操作系统中的优秀思想是随着工程师的学习和时间逐渐积累的。此处我们只会讨论一些主要发展。如果想要了解更多，请参阅Brinch Hansen对操作系统历史的杰出叙述{{ "BH00" | cite }}。

### 2.6.1 早期操作系统：只有库

开始的时候操作系统所做的事情并不多。它基本上只是一系列经常使用的函数的库的集合；比如说，“操作系统”会提供底层的I/O处理代码的API，这样程序员就不用再重写一遍这些代码，生活变得更简单了。

通常来说，这些旧的大型机（mainframe）系统由人类操作员来进行控制，一次只运行一个程序。大多数现代操作系统的工作（比如确定用什么顺序执行任务）都是由这位操作员完成的。如果你是个聪明的开发者，你就需要和这位操作员搞好关系，这样他们就可能会帮你把任务移到队列前面。

因为这种执行方式中，是先设置好一系列任务，然后由操作员“成批”执行这些任务，这种方式被称为**批处理**（batch processing）。此时的计算机并不能用交互的方式来使用，因为这样成本太高：如果只有一个用户坐在计算机前使用它，那么大部分时候计算机都是闲置的，然而运行一个小时的成本就有成千上万美元，这样做实在是太浪费了{{ "BH00" | cite }}。

### 2.6.2 除了库之外：保护

操作系统很快在控制机器方面获得了中心地位，不只是通用设备的简单程序库了。人们很快意识到，操作系统代码能够控制外部设备，它和普通应用代码是不同的。为什么呢？那么想象一下，如果你允许任何应用从磁盘的任何位置读取数据的话，隐私的概念就消失不见了，因为任何程序都可以读任意文件。因此，把**文件系统**（用于管理文件）作为库代码是没有什么意义的，我们需要的是别的东西。

因此，人们发明了**系统调用**的概念，Atlas计算系统成为了这一理念的先驱者{{ "K_61" | cite }}{{ "L78" | cite }}。这一思想并不是将操作系统的功能作为库提供（此时你只需进行**程序调用**（procedure call）来访问这些功能），而是在硬件中添加一些特殊的指令和状态，用来将控制权转交给操作系统。

系统调用和程序调用最关键的区别是，系统调用会将控制权转交给（跳转到）操作系统，这导致了**硬件权限级别**（hradware privilege level）的产生。用户应用运行在**用户态**（user mode）中，这意味着这些应用在硬件权限方面受到了一些限制；不如说，用户态下运行的应用一般不能启动对磁盘的I/O请求，访问物理内存页，或者向网络中发送数据包。当系统调用启动时（通常是通过一种叫**陷阱**（trap）的特殊硬件指令），硬件将控制权移交给事先定义好的**陷阱处理程序**（trap handler）（操作系统事先设定好的），同时将优先级提升至**核心态**（kernal mode）。在核心态中，操作系统拥有对系统硬件的全部访问权限，可以启动I/O请求或者为程序分配更多内存。当操作系统完成请求之后，它就会用一条特殊的**陷阱返回**（return-from-trap）指令将控制权交还给用户，同时将优先级降低到用户态。

### 2.6.3 多道程序的时代

操作系统真正产生飞跃式的发展是在大型机的时代结束，**小型机**（minicomputer）的时代开始时。迪吉多电脑公司（Digital Equipment）推出的迷你电脑（PDP，Programmed Data Processor）使电脑价格大幅度下降；因此，一个大的机构内不必再购买一台大型机，而可以让一少部分人拥有自己的计算机。毫不出奇的是，这次电脑价格的降低大大提升了开发者的兴趣；更多聪明人开始接触计算机，让计算机系统做出更多优美有趣的事情。

为了更好地利用机器资源，**多道程序**（multiprogramming）变得非常流行。操作系统不再只同时运行一项任务，而是把一定数量的任务加载到内存中，并迅速地在任务之间切换，以此提高CPU的利用率。这种切换是非常重要的，因为I/O设备的速度很慢；让程序在CPU上暂停等待I/O完成是浪费时间。那么，为什么不切换到另一项任务并运行一段时间呢？

对多道程序、I/O时程序执行重叠和中断的需求使得操作系统许多方向的概念有了很大的发展。**存储保护**（memory protection）的概念变得重要起来；我们不希望一个程序能够访问别的程序的内存。解决多道程序导致的**并发**问题也变得至关重要；保证操作系统在发生中断时能够正确继续执行也是一个很大的挑战。我们会在后面的部分中学到这些问题和相关主题。

UNIX操作系统的产生是当时的巨大进步之一，主要贡献者是贝尔实验室（是的，那个电话公司）的Ken Thompson（和Dennis Ritchie）。UNIX从各种操作系统中获得了很多灵感（特别是Multics{{ "O72" | cite }}，还有TENEX{{ "B_72" | cite }}和伯克利分时系统（Berkeley Time-Sharing System）{{ "S_68" | cite }}中的一些内容），而且让它们更简单易用了。很快，这一团队就开始将包含UNIX源代码的磁带运输给世界各地的人，其中的很多人之后也开始参与到UNIX系统的编写之中；细节详见下面的**旁白**[^10]。

<table><tr><td bgcolor=#E6E6E6>
<p style="text-align: center;">旁白：<strong>UNIX系统的重要性</strong></p>

<p>无论怎么强调UNIX在操作系统历史发展中的重要性都不过分。UNIX受到了早期操作系统的启发（特别是MIT的著名系统，<strong>Multics</strong>），集合了很多非常棒的思想，并构建了一个既简单又强大的系统。</p>

<p>原先的“贝尔实验室”版本的UNIX的设计原则是，构建小而强大的子程序，然后把它们连接在一起，构成更大的工作流。用于键入指令的<strong>终端</strong>（shell）提供了<strong>管道</strong>（pipe）等基础功能用来支持这一元层次的编程，因此用不同的程序来共同完成一个大任务变得很容易。例如，为了在一个文本文件中找出包含“foo”字符串的行，你只需键入<code>grep foo file.txt|wc -l</code>，连续使用<code>grep</code>和<code>wc</code>（字数统计）工具来完成这项工作。</p>

<p>UNIX操作系统的环境对程序员和开发者也很友好，而且还为新的<strong>C语言</strong>提供了编译器。因为UNIX使得程序员撰写和分享程序变得更加容易，UNIX变得非常流行起来。它可能还推动了<strong>开源软件</strong>的形成，作者愿意把软件源代码分享给任何一个想要的人。</p>

<p>UNIX的另一个关键特点是代码的可达性和可读性。UNIX的内核由优雅简短的C代码写成，这就使得别人愿意阅读内核代码并在其中加入新的特征。比如，伯克利的<strong>Bill Joy</strong>领导的一个企业团队就以UNIX为基础开发了一个极好的发行版（<strong>Berkeley Systems Distribution</strong>，缩写为<strong>BSD</strong>），它拥有很多先进的子系统，包括虚拟内存、文件系统和网络。Joy之后成为了<strong>太阳微系统公司</strong>（Sun Microsystems）的共同创始人之一。</p>

<p>不幸的是，因为很多公司试图获得UNIX的所有权并从中获利，律师开始参与进这一过程中，UNIX的传播减缓了。很多公司都开发了自己的版本：太阳微系统的<strong>SunOS</strong>，IBM的<strong>AIX</strong>，惠普的<strong>HPUX</strong>（又名“H-Pucks”），以及SGI的<strong>IRIX</strong>。AT&T和贝尔实验室以及其他公司之间的法律纠纷给UNIX蒙上了一层暗影，很多人并不相信它会存活下去，特别是Windows已经占领了大部分PC市场的时候……</p>

</td></tr></table>


### 2.6.4 新时代

小型机之后，另一种更便宜，运行速度更快，为大众准备的计算机出现了：我们现在称它为**个人电脑**（personal computer，缩写为PC）。这类新计算机的最初代表是苹果的早期及其（比如Apple II）和IBM PC，它们很快成为了计算领域的核心力量，因为它们的价格十分低廉，用每个桌面上的一台电脑取代了每个工作组的一台共享小型机。

不幸的是，PC早期的操作系统大大倒退了，好像完全忘记了（或者完全不知道）小型机时代学到的教训。比如说，**DOS**（**Disk Operating System**的缩写，是**微软**开发的操作系统）之类的早期操作系统就不认为内存保护是重要的；因此，一个恶意软件（或者很可能仅仅是写错了的软件）可以把内存全部搞乱。第一代**苹果操作系统**（Mac OS）（v9及之前版本）在作业调度（job scheduling）方面也同步开了倒车：进入无限死循环的线程会占据整个系统，唯一的解决方法是冲洗。这一代操作系统中缺失的特性实在是太长太悲哀了，长得不适合在此处全部列举出来。

幸运的是，在几年的痛苦之后，个人电脑终于开始采用小型机系统的一些特性。比如，Mac OS X和macOS的系统内核是UNIX，因此包括了这一成熟系统中的全部特性。从Windows NT开始，Windows操作系统也逐渐采取了计算机历史上的许多伟大思想，这是微软操作系统技术的一大进步。比起上世纪八十年代的PC系统，现代手机运行的操作系统（比如Linux）更像七十年代的小型机系统（谢天谢地）。操作系统发展的全盛期产生的思想仍能在现代系统中发挥作用，实在是太好了。更好的是，这些思想仍在不断发展，提供了更多的特性，使得现代系统对用户和应用更友好了。

<table><tr><td bgcolor=#E6E6E6>
<p style="text-align: center;">旁白：<strong>LINUX的及时出现</strong></p>

<p>对UNIX来说，幸运的是，一位叫<strong>Linus Torvalds</strong>的年轻芬兰黑客决定编写自己版本的UNIX，这一版本借用了原有系统的许多设计原则和思想，但并没有依赖原来的代码，这规避了版权问题。他从世界各地寻求帮助，很快<strong>Linux</strong>就诞生了（现代开源软件运动也一并诞生了）。</p>

<p>互联网时代来临后，大多数公司（包括谷歌、亚马逊和脸书等等）决定使用Linux系统，因为它免费，而且可以迅速修改以适应需求。的确，如果没有Linux系统，很难想象这些公司会大获成功。因为相似的原因，Linux在智能手机的发展中也占据了重要地位。乔布斯把他的基于UNIX的<strong>NeXTStep</strong>操作系统带到了苹果，这使得UNIX在笔记本电脑上也流行起来（虽然现在的很多苹果用户可能根本没有意识到这一事实）。因此，UNIX存活了下来，地位比之前还要更高。如果你相信有计算机上帝，那你应该为为此而感谢他们。</p>

</td></tr></table>

## 2.7

至此，我们对操作系统的基本介绍结束了。如今的操作系统已经相当易用了。实际上，我们今天所使用的全部操作系统都受到了我们将在本书中谈到的发展阶段的影响。

不幸的是，由于时间限制，本书不会涉及操作系统的其他很多部分。比如，操作系统中还有很多与网络相关的代码；我们把这些留给你在网络相关课程上去了解。再比如，图形设备是特别重要的；如果想扩展这方面的知识，请上一些图形学方面的课程。最后，有些操作系统方面的书会讲到一大堆与**安全**（security）有关的东西；我们只会在讲解程序之间的保护机制和保护用户文件的时候涉及这一方面，不会讲到更深层次的安全问题，那些通常出现在安全相关课程中的问题。

不过，我们仍将讲解很多重要的主题，包括CPU和内存的虚拟化、并发、设备和文件系统的持久化等方面的基本知识。别担心！虽然还有很多东西要学，但学的东西都很酷，到学习结束的时候，你会对计算机系统如何运行产生崭新的认识。现在，让我们去学习吧！

---

[^1] 显然，为了使程序运行得更快，现代处理器暗中做了很多骇人听闻的事情，比如同时执行多条指令，甚至乱序发射和执行指令！但我们并不关心这些；我们只关心大部分程序假设的简单模型：指令按顺序执行，一次只执行一条。

[^2] 冯·诺依曼是计算机领域的先驱者之一。他同时也在博弈论和原子弹领域进行了开创性的工作，并在NBA中打了六年球。好吧，以上有一件事不是真的。（译者：在NBA打球不是真的。）

[^3] 操作系统的其他早期名称包括**监督程序**（supervisor），以及**中央控制程序**（master control program）。显然，第二个名字听起来有点过于心急了（细节请见电影《电子世界争霸战》（Tron））；因此，谢天谢地，最终人们采用了“操作系统”这一名称。（译者：“中央控制程序”是[该电影](https://en.wikipedia.org/wiki/Tron)中不愿被人操纵而想掌控世界的人工智能的名字。）

[^4] 我们使用`&`符号来同时运行四个进程。在`tcsh`终端中，这样做会在后台启动这些程序，也就意味着用户可以立即给出下一条指令，此处是下一个要运行的程序。在`tcsh`中，命令之间的分号允许我们同时运行多个程序。如果你使用的是其他终端（比如`bash`），表现会有一些不同，具体请阅读在线文档。

[^5] 为了使这个例子能够工作，你需要关闭地址空间随机化（address-space randomization）；事实上，随机化可以很好地抵挡某些安全漏洞。如果你想了解如何通过栈溢出攻击破解计算机系统，请自己阅读更多相关内容。当然这并不是说我们建议这么做……

[^6] 实际调用的是首字母小写的`pthread_create()`函数；首字母大写的版本是我们自己对这一函数的封装，它会调用`pthread_create()`并保证该函数返回成功。详情请见代码。

[^7] 你应该用Emacs。如果你用的是vi，那么你的脑子大概是出了什么问题。如果你用的不是一个真正的代码编辑器，那你的状况甚至更糟。（译者：我不服，这些翻译都是我用notepad++敲出来的！）

[^8] 设备驱动器是操作系统中能够和特定设备交互的代码。我们之后还会再讨论到设备和设备驱动器。

[^9] 你们有些人可能会反对将C称为高级语言。但是记住，这是一堂操作系统课，我们不用整天写汇编就已经非常开心啦！

[^10] 我们会用旁白和其他相关的文本框用来叙述一些与正文关系不大的东西。有时我们甚至会用旁白来开玩笑，难道学习不能变的更有趣一点吗？当然，很多笑话都不怎么好笑。